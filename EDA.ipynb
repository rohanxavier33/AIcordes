{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Set the paths\n",
    "data_dir = Path('data/McGill-Billboard')\n",
    "chordino_dir = data_dir / 'chordino'\n",
    "lab_dir = data_dir / 'lab'\n",
    "annotations_dir = data_dir / 'annotations'\n",
    "index_path = data_dir / 'index.csv'\n",
    "\n",
    "# 1. Dataset Overview\n",
    "print(\"Loading the dataset index\")\n",
    "index_df = pd.read_csv(index_path)\n",
    "print(f\"Total entries in index: {len(index_df)}\")\n",
    "print(f\"Entries with complete data: {index_df['title'].notna().sum()}\")\n",
    "\n",
    "# Drop entries with missing data\n",
    "index_df = index_df.dropna(subset=['title'])\n",
    "print(f'Total entries after cleaning: {len(index_df)}')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Number of unique songs: {index_df['title'].nunique()}\")\n",
    "print(f\"Number of unique artists: {index_df['artist'].nunique()}\")\n",
    "\n",
    "# Convert chart_date to datetime\n",
    "index_df['chart_date'] = pd.to_datetime(index_df['chart_date'])\n",
    "\n",
    "# Extract year and decade\n",
    "index_df['year'] = index_df['chart_date'].dt.year\n",
    "index_df['decade'] = (index_df['year'] // 10) * 10\n",
    "\n",
    "# Analyze the decade distribution\n",
    "decade_counts = index_df['decade'].value_counts().sort_index()\n",
    "print(\"\\nSongs per decade:\")\n",
    "print(decade_counts)\n",
    "\n",
    "# Visualize the distribution of songs per decade\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=decade_counts.index, y=decade_counts.values)\n",
    "plt.title('Number of Songs per Decade')\n",
    "plt.xlabel('Decade')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.savefig('songs_per_decade.png')\n",
    "plt.show()\n",
    "\n",
    "# 2. Checking Data Availability\n",
    "song_ids = [d.name for d in chordino_dir.iterdir() if d.is_dir()]\n",
    "print(f\"\\nNumber of songs with chroma features: {len(song_ids)}\")\n",
    "\n",
    "# Check if the same songs have lab files\n",
    "lab_ids = [d.name for d in lab_dir.iterdir() if d.is_dir()]\n",
    "print(f\"Number of songs with lab files: {len(lab_ids)}\")\n",
    "\n",
    "# Find songs that have both chroma and labels\n",
    "common_ids = set(song_ids).intersection(set(lab_ids))\n",
    "print(f\"Number of songs with both features and labels: {len(common_ids)}\")\n",
    "\n",
    "# 3. Explore Chroma Features\n",
    "example_id = list(common_ids)[random.randint(0, len(common_ids)-1)]\n",
    "print(f\"\\nExploring example song ID: {example_id}\")\n",
    "\n",
    "# Load chroma features for the example song\n",
    "chroma_path = chordino_dir / example_id / 'bothchroma.csv'\n",
    "tuning_path = chordino_dir / example_id / 'tuning.csv'\n",
    "\n",
    "if chroma_path.exists() and tuning_path.exists():\n",
    "    chroma_data = pd.read_csv(chroma_path, header=None)\n",
    "    tuning_data = pd.read_csv(tuning_path, header=None)\n",
    "    \n",
    "    print(f\"Chroma shape for song {example_id}: {chroma_data.shape}\")\n",
    "    print(f\"Tuning shape for song {example_id}: {tuning_data.shape}\")\n",
    "    \n",
    "    # Display a sample of the chroma data\n",
    "    print(\"\\nSample of chroma data:\")\n",
    "    print(chroma_data.head())\n",
    "    \n",
    "    # Plot chroma data as a heatmap\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    # Skip the first column (metadata) and use only pitch data\n",
    "    try:\n",
    "        # Try to get chroma columns (usually columns 2-13)\n",
    "        chroma_plot_data = chroma_data.iloc[:100, 2:14].astype(float)  # First 100 rows for visibility\n",
    "        sns.heatmap(chroma_plot_data.T, cmap='viridis', cbar=True)\n",
    "        plt.title(f'Chroma Feature Heatmap for Song {example_id} (First 100 frames)')\n",
    "        plt.xlabel('Time frames')\n",
    "        plt.ylabel('Pitch Class (C, C#, D, D#, E, F, F#, G, G#, A, A#, B)')\n",
    "        plt.savefig('chroma_heatmap.png')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating heatmap: {e}\")\n",
    "else:\n",
    "    print(f\"Chroma or tuning data not found for song {example_id}\")\n",
    "\n",
    "# 4. Explore Chord Labels\n",
    "lab_path = lab_dir / example_id / \"full.lab\"\n",
    "\n",
    "if lab_path.exists():\n",
    "    # Read the lab file (tab-separated with no header)\n",
    "    lab_data = pd.read_csv(lab_path, sep='\\t', header=None, names=['start_time', 'end_time', 'chord'])\n",
    "    \n",
    "    print(f\"\\nNumber of chord segments for song {example_id}: {len(lab_data)}\")\n",
    "    print(\"\\nSample of chord labels:\")\n",
    "    print(lab_data.head())\n",
    "    \n",
    "    # Count the unique chords in this song\n",
    "    print(f\"\\nNumber of unique chords in song {example_id}: {lab_data['chord'].nunique()}\")\n",
    "    \n",
    "    # Most common chords in this song\n",
    "    most_common_chords = lab_data['chord'].value_counts().head(10)\n",
    "    print(\"\\nMost common chords in this song:\")\n",
    "    print(most_common_chords)\n",
    "    \n",
    "    # Plot the distribution of chord types\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    most_common_chords.plot(kind='bar')\n",
    "    plt.title(f'Most Common Chords in Song {example_id}')\n",
    "    plt.xlabel('Chord')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('common_chords.png')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Lab file not found for song {example_id}\")\n",
    "\n",
    "# 5. Analyze Chord Classes Across the Dataset\n",
    "def analyze_chord_distribution(song_ids, max_songs=100):\n",
    "    \"\"\"Analyze the distribution of chord classes across multiple songs\"\"\"\n",
    "    all_chords = []\n",
    "    processed_songs = 0\n",
    "    \n",
    "    for song_id in tqdm(song_ids, desc=\"Analyzing chords\"):\n",
    "        if processed_songs >= max_songs:\n",
    "            break\n",
    "            \n",
    "        lab_path = lab_dir / song_id / \"full.lab\"\n",
    "        if lab_path.exists():\n",
    "            lab_data = pd.read_csv(lab_path, sep='\\t', header=None, names=['start_time', 'end_time', 'chord'])\n",
    "            all_chords.extend(lab_data['chord'].tolist())\n",
    "            processed_songs += 1\n",
    "    \n",
    "    # Count chord occurrences\n",
    "    chord_counts = Counter(all_chords)\n",
    "    \n",
    "    # Analyze basic chord types\n",
    "    chord_types = []\n",
    "    for chord in chord_counts.keys():\n",
    "        if ':' in chord:\n",
    "            chord_type = chord.split(':')[1]\n",
    "            # Extract the base type (before any parentheses or additional modifiers)\n",
    "            base_type = re.split(r'[\\(\\)/]', chord_type)[0]\n",
    "            chord_types.append(base_type)\n",
    "    \n",
    "    type_counts = Counter(chord_types)\n",
    "    \n",
    "    return chord_counts, type_counts\n",
    "\n",
    "# Sample a subset of songs to analyze\n",
    "sample_size = min(100, len(common_ids))\n",
    "sample_ids = random.sample(list(common_ids), sample_size)\n",
    "\n",
    "# Analyze chord distribution\n",
    "chord_counts, type_counts = analyze_chord_distribution(sample_ids)\n",
    "\n",
    "print(f\"\\nAnalyzed chord distribution across {sample_size} songs\")\n",
    "print(f\"Total unique chords: {len(chord_counts)}\")\n",
    "print(f\"Total chord instances: {sum(chord_counts.values())}\")\n",
    "\n",
    "# Plot the distribution of chord types\n",
    "plt.figure(figsize=(12, 6))\n",
    "common_types = {k: v for k, v in sorted(type_counts.items(), key=lambda x: x[1], reverse=True)[:15]}\n",
    "plt.bar(common_types.keys(), common_types.values())\n",
    "plt.title('Distribution of Chord Types')\n",
    "plt.xlabel('Chord Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('chord_type_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot the distribution of the most common chords\n",
    "plt.figure(figsize=(12, 6))\n",
    "common_chords = {k: v for k, v in sorted(chord_counts.items(), key=lambda x: x[1], reverse=True)[:20]}\n",
    "plt.bar(common_chords.keys(), common_chords.values())\n",
    "plt.title('Most Common Chords')\n",
    "plt.xlabel('Chord')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('common_chords_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# 6. Analyze the relationship between chroma features and chords\n",
    "def analyze_chroma_chord_relationship(song_id):\n",
    "    \"\"\"Analyze the relationship between chroma features and chords for a single song\"\"\"\n",
    "    chroma_path = chordino_dir / song_id / 'bothchroma.csv'\n",
    "    lab_path = lab_dir / song_id / \"full.lab\"\n",
    "    \n",
    "    if not (chroma_path.exists() and lab_path.exists()):\n",
    "        return None\n",
    "    \n",
    "    # Load chroma data\n",
    "    chroma_data = pd.read_csv(chroma_path, header=None)\n",
    "    \n",
    "    # Extract chroma features (columns 2-13 usually contain the 12 pitch classes)\n",
    "    if chroma_data.shape[1] >= 14:\n",
    "        # Skip first row and first two columns (metadata)\n",
    "        chroma_array = chroma_data.iloc[1:, 2:14].values.astype(np.float32)\n",
    "        times = chroma_data.iloc[1:, 1].values.astype(np.float32)\n",
    "    else:\n",
    "        # If format is different, try to handle it\n",
    "        for col in chroma_data.columns:\n",
    "            chroma_data[col] = pd.to_numeric(chroma_data[col], errors='coerce')\n",
    "        \n",
    "        numeric_data = chroma_data.dropna(axis=1)\n",
    "        times = numeric_data.iloc[:, 0].values.astype(np.float32)\n",
    "        chroma_array = numeric_data.iloc[:, 1:13].values.astype(np.float32)\n",
    "    \n",
    "    # Load chord labels\n",
    "    lab_data = pd.read_csv(lab_path, sep='\\t', header=None, names=['start_time', 'end_time', 'chord'])\n",
    "    \n",
    "    # Create a list to store chord for each chroma frame\n",
    "    chroma_chords = []\n",
    "    \n",
    "    # For each chroma frame, find the corresponding chord\n",
    "    for i, time in enumerate(times):\n",
    "        # Find the chord at this time\n",
    "        chord_idx = ((lab_data['start_time'] <= time) & (lab_data['end_time'] > time))\n",
    "        if chord_idx.any():\n",
    "            chord = lab_data.loc[chord_idx.idxmax(), 'chord']\n",
    "        else:\n",
    "            chord = \"N\"  # No chord\n",
    "        \n",
    "        chroma_chords.append(chord)\n",
    "    \n",
    "    # Create a dictionary to store average chroma vectors for each chord\n",
    "    chord_chroma_avg = {}\n",
    "    \n",
    "    # Calculate average chroma vector for each chord\n",
    "    for chord in set(chroma_chords):\n",
    "        # Find all frames with this chord\n",
    "        chord_frames = [i for i, c in enumerate(chroma_chords) if c == chord]\n",
    "        \n",
    "        # Calculate average chroma vector\n",
    "        if chord_frames:\n",
    "            avg_vector = np.mean(chroma_array[chord_frames], axis=0)\n",
    "            chord_chroma_avg[chord] = avg_vector\n",
    "    \n",
    "    return chord_chroma_avg\n",
    "\n",
    "# Analyze chroma-chord relationship for an example song\n",
    "example_chord_chroma = analyze_chroma_chord_relationship(example_id)\n",
    "\n",
    "if example_chord_chroma:\n",
    "    # Plot average chroma vectors for the most common chords\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Get the most common chords (limit to 5 for visibility)\n",
    "    common_chords = lab_data['chord'].value_counts().head(5).index.tolist()\n",
    "    \n",
    "    for i, chord in enumerate(common_chords):\n",
    "        if chord in example_chord_chroma:\n",
    "            plt.subplot(len(common_chords), 1, i+1)\n",
    "            plt.bar(range(12), example_chord_chroma[chord])\n",
    "            plt.title(f'Average Chroma Vector for Chord: {chord}')\n",
    "            plt.xticks(range(12), ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'])\n",
    "            plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('chord_chroma_relationship.png')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Could not analyze chroma-chord relationship for the example song\")\n",
    "\n",
    "# 7. Simplifying Chord Classes\n",
    "def simplify_chord(chord):\n",
    "    \"\"\"Simplify chord labels to reduce the number of classes\"\"\"\n",
    "    # Special case for no chord\n",
    "    if chord == 'N':\n",
    "        return 'N'\n",
    "        \n",
    "    # Remove extensions and inversions\n",
    "    if ':' in chord:\n",
    "        root, quality = chord.split(':', 1)\n",
    "        \n",
    "        # Extract basic quality\n",
    "        if quality.startswith('maj'):\n",
    "            return f\"{root}:maj\"\n",
    "        elif quality.startswith('min'):\n",
    "            return f\"{root}:min\"\n",
    "        elif quality.startswith('dim'):\n",
    "            return f\"{root}:dim\"\n",
    "        elif quality.startswith('aug'):\n",
    "            return f\"{root}:aug\"\n",
    "        elif quality.startswith('7'):\n",
    "            return f\"{root}:7\"\n",
    "        elif quality.startswith('sus'):\n",
    "            return f\"{root}:sus\"\n",
    "        else:\n",
    "            # Default to major if quality is complex\n",
    "            return f\"{root}:maj\"\n",
    "    else:\n",
    "        # No quality specified, assume major\n",
    "        return f\"{chord}:maj\"\n",
    "\n",
    "# Analyze original vs simplified chord distribution\n",
    "original_chords = []\n",
    "simplified_chords = []\n",
    "\n",
    "for song_id in tqdm(sample_ids, desc=\"Analyzing chord simplification\"):\n",
    "    lab_path = lab_dir / song_id / \"full.lab\"\n",
    "    if lab_path.exists():\n",
    "        lab_data = pd.read_csv(lab_path, sep='\\t', header=None, names=['start_time', 'end_time', 'chord'])\n",
    "        \n",
    "        for chord in lab_data['chord'].tolist():\n",
    "            original_chords.append(chord)\n",
    "            simplified_chords.append(simplify_chord(chord))\n",
    "\n",
    "original_count = len(set(original_chords))\n",
    "simplified_count = len(set(simplified_chords))\n",
    "\n",
    "print(f\"\\nOriginal unique chord classes: {original_count}\")\n",
    "print(f\"Simplified unique chord classes: {simplified_count}\")\n",
    "print(f\"Reduction: {original_count - simplified_count} classes ({(original_count - simplified_count) / original_count * 100:.2f}%)\")\n",
    "\n",
    "# Plot the reduction in chord classes\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(['Original', 'Simplified'], [original_count, simplified_count])\n",
    "plt.title('Reduction in Chord Classes with Simplification')\n",
    "plt.ylabel('Number of Unique Chord Classes')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.savefig('chord_simplification.png')\n",
    "plt.show()\n",
    "\n",
    "# 8. Summary and Conclusions\n",
    "print(\"\\n=== EDA Summary ===\")\n",
    "print(f\"• Dataset contains {len(index_df)} songs spanning from the 1950s to 1990s\")\n",
    "print(f\"• The dataset has {len(chord_counts)} unique chord classes\")\n",
    "print(f\"• Simplifying chords reduces the number of classes from {original_count} to {simplified_count}\")\n",
    "print(f\"• Chroma features provide a 12-dimensional vector representing pitch class intensities\")\n",
    "print(f\"• Each song has an average of {sum(chord_counts.values()) / sample_size:.1f} chord segments\")\n",
    "print(\"• The dataset provides a rich source for training chord recognition models\")\n",
    "print(\"• Memory efficiency will be critical given the large number of chord classes and data points\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
