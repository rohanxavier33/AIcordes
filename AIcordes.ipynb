{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Conv1D, MaxPooling1D, Flatten, Input, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths\n",
    "data_dir = Path('data/McGill-Billboard')\n",
    "chordino_dir = data_dir / 'chordino'\n",
    "lab_dir = data_dir / 'lab'\n",
    "annotations_dir = data_dir / 'annotations'\n",
    "index_path = index_path = data_dir / 'index.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset index\n",
    "index_df = pd.read_csv(index_path)\n",
    "print(f\"Total entries in index: {len(index_df)}\")\n",
    "print(f\"Entries with complete data: {index_df['title'].notna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop entries with missing incomplete/unavailable data\n",
    "index_df = index_df.dropna(subset=['title'])\n",
    "\n",
    "# Verify new dataframe\n",
    "print(f'Total Entries after cleaning: {len(index_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(f\"Number of unique songs: {index_df['title'].nunique()}\")\n",
    "print(f\"Number of unique artists: {index_df['artist'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert chart_date to datetime\n",
    "index_df['chart_date'] = pd.to_datetime(index_df['chart_date'])\n",
    "\n",
    "# Extract year and decade\n",
    "index_df['year'] = index_df['chart_date'].dt.year\n",
    "index_df['decade'] = (index_df['year'] // 10) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_counts = index_df['decade'].value_counts().sort_index()\n",
    "\n",
    "print(decade_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available directories\n",
    "song_ids = [d.name for d in chordino_dir.iterdir() if d.is_dir()]\n",
    "print(f\"Number of songs with chroma features: {len(song_ids)}\")\n",
    "\n",
    "# Check if the same songs have lab files\n",
    "lab_ids = [d.name for d in lab_dir.iterdir() if d.is_dir()]\n",
    "print(f\"Number of songs with lab files: {len(lab_ids)}\")\n",
    "\n",
    "# Find songs that have both chroma and labels\n",
    "common_ids = set(song_ids).intersection(set(lab_ids))\n",
    "print(f\"Number of songs with both features and labels: {len(common_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore one example\n",
    "example_id = list(common_ids)[random.randint(0, len(common_ids))]\n",
    "\n",
    "# Load chroma features for the example song\n",
    "chroma_path = chordino_dir / example_id / 'bothchroma.csv'\n",
    "tuning_path = chordino_dir / example_id / 'tuning.csv'\n",
    "\n",
    "if chroma_path.exists() and tuning_path.exists():\n",
    "    chroma_data = pd.read_csv(chroma_path, header=None)\n",
    "    tuning_data = pd.read_csv(tuning_path, header=None)\n",
    "    \n",
    "    print(f\"\\nChroma shape for song {example_id}: {chroma_data.shape}\")\n",
    "    print(f\"Tuning shape for song {example_id}: {tuning_data.shape}\")\n",
    "    \n",
    "    # Display a sample of the chroma data\n",
    "    print(\"\\nSample of chroma data:\")\n",
    "    print(chroma_data.head())\n",
    "else:\n",
    "    print(f\"Chroma or tuning data not found for song {example_id}\")\n",
    "\n",
    "# Load chord labels for the example song\n",
    "lab_path = lab_dir / example_id / \"full.lab\"\n",
    "\n",
    "if lab_path.exists():\n",
    "    # Read the lab file (tab-separated with no header)\n",
    "    lab_data = pd.read_csv(lab_path, sep='\\t', header=None, names=['start_time', 'end_time', 'chord'])\n",
    "    \n",
    "    print(f\"\\nNumber of chord segments for song {example_id}: {len(lab_data)}\")\n",
    "    print(\"\\nSample of chord labels:\")\n",
    "    print(lab_data.head())\n",
    "    \n",
    "    # Count the unique chords in this song\n",
    "    print(f\"\\nNumber of unique chords in song {example_id}: {lab_data['chord'].nunique()}\")\n",
    "    print(\"\\nMost common chords:\")\n",
    "    print(lab_data['chord'].value_counts().head(10))\n",
    "else:\n",
    "    print(f\"Lab file not found for song {example_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Chroma shape for song {example_id}: {chroma_data.shape}\")\n",
    "print(\"\\nSample of chroma data:\")\n",
    "print(chroma_data.head())\n",
    "\n",
    "# Plot chroma data\n",
    "plt.figure(figsize=(12, 4))\n",
    "sns.heatmap(chroma_data.iloc[:, 2:].T, cmap='coolwarm', cbar=True)\n",
    "plt.title(f'Chroma Feature Heatmap for Song {example_id}')\n",
    "plt.xlabel('Time frames')\n",
    "plt.ylabel('Pitch Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load chord labels\n",
    "lab_data = pd.read_csv(lab_dir / example_id / \"full.lab\", sep='\\t', names=['start', 'end', 'chord'])\n",
    "\n",
    "print(f\"Number of chord segments for song {example_id}: {len(lab_data)}\")\n",
    "print(\"\\nSample of chord segments:\")\n",
    "print(lab_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique chords\n",
    "unique_chords = lab_data['chord'].nunique()\n",
    "print(f\"Number of unique chords in song {example_id}: {unique_chords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most frequent chords\n",
    "most_common_chords = lab_data['chord'].value_counts().head(10)\n",
    "print(\"Most common chords:\")\n",
    "print(most_common_chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chroma(song_id):\n",
    "    \"\"\"Load chroma features for a given song ID\"\"\"\n",
    "    chroma_path = chordino_dir / song_id / 'bothchroma.csv'\n",
    "    \n",
    "    if not chroma_path.exists():\n",
    "        return None\n",
    "    \n",
    "    # Read the file as text first to understand the structure\n",
    "    with open(chroma_path, 'r') as f:\n",
    "        first_line = f.readline().strip()\n",
    "    \n",
    "    # Check the structure of the file\n",
    "    columns = first_line.split(',')\n",
    "    \n",
    "    # Based on your description, we need to handle two different formats\n",
    "    if len(columns) >= 14:  # First two columns are non-numeric, followed by 12 chroma values\n",
    "        # Load the chroma features, skipping the non-numeric metadata columns\n",
    "        chroma_data = pd.read_csv(chroma_path, header=None, usecols=range(2, 14))\n",
    "    else:\n",
    "        # If the format is different, try to determine which columns contain the chroma features\n",
    "        # For now, we'll just use all columns and convert non-numeric to NaN\n",
    "        chroma_data = pd.read_csv(chroma_path, header=None)\n",
    "        # Convert to numeric, coercing errors to NaN\n",
    "        for col in chroma_data.columns:\n",
    "            chroma_data[col] = pd.to_numeric(chroma_data[col], errors='coerce')\n",
    "        # Drop columns with NaN values (these are likely non-numeric metadata columns)\n",
    "        chroma_data = chroma_data.dropna(axis=1)\n",
    "    \n",
    "    # Convert to numpy array, ensuring all values are numeric\n",
    "    chroma_array = chroma_data.values.astype(np.float32)\n",
    "    \n",
    "    # Check for invalid values and replace with zeros\n",
    "    chroma_array = np.nan_to_num(chroma_array)\n",
    "    \n",
    "    return chroma_array\n",
    "\n",
    "def load_chord_labels(song_id):\n",
    "    \"\"\"Load chord labels for a given song ID\"\"\"\n",
    "    lab_path = lab_dir / song_id / \"full.lab\"\n",
    "    \n",
    "    if not lab_path.exists():\n",
    "        return None\n",
    "    \n",
    "    # Load the chord labels\n",
    "    lab_data = pd.read_csv(lab_path, sep='\\t', header=None, names=['start_time', 'end_time', 'chord'])\n",
    "    \n",
    "    return lab_data\n",
    "\n",
    "def get_chroma_timestamps(chroma_array, hop_size=0.01):\n",
    "    \"\"\"Generate timestamps for chroma features\"\"\"\n",
    "    # Chordino typically uses a 0.01s hop size (10ms)\n",
    "    return np.arange(len(chroma_array)) * hop_size\n",
    "\n",
    "def align_chroma_with_chords(chroma_array, chord_data, chroma_hop_size=0.01):\n",
    "    \"\"\"Align chroma features with chord labels\"\"\"\n",
    "    chroma_times = get_chroma_timestamps(chroma_array, chroma_hop_size)\n",
    "    aligned_chords = []\n",
    "    \n",
    "    for i, time in enumerate(chroma_times):\n",
    "        # Find the chord label for this time point\n",
    "        chord_idx = ((chord_data['start_time'] <= time) & (chord_data['end_time'] > time)).idxmax()\n",
    "        if pd.isna(chord_idx):  # No matching chord found\n",
    "            chord = \"N\"  # No chord (silence or undefined)\n",
    "        else:\n",
    "            chord = chord_data.loc[chord_idx, 'chord']\n",
    "        \n",
    "        aligned_chords.append(chord)\n",
    "    \n",
    "    return aligned_chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(song_ids, max_songs=100):\n",
    "    \"\"\"Build a dataset of chroma features and chord labels\"\"\"\n",
    "    X = []  # Chroma features\n",
    "    y = []  # Chord labels\n",
    "    \n",
    "    processed_songs = 0\n",
    "    all_chords = []\n",
    "    failed_songs = 0\n",
    "    \n",
    "    for song_id in tqdm(song_ids):\n",
    "        if processed_songs >= max_songs:\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            # Load chroma and chord data\n",
    "            chroma_array = load_chroma(song_id)\n",
    "            chord_data = load_chord_labels(song_id)\n",
    "            \n",
    "            if chroma_array is None or chord_data is None:\n",
    "                continue\n",
    "                \n",
    "            # Make sure chroma data is strictly numerical and contains no NaNs or Infs\n",
    "            if not np.isfinite(chroma_array).all():\n",
    "                print(f\"Warning: Song {song_id} has non-finite values in chroma. Skipping.\")\n",
    "                failed_songs += 1\n",
    "                continue\n",
    "                \n",
    "            # Align chroma with chords\n",
    "            aligned_chords = align_chroma_with_chords(chroma_array, chord_data)\n",
    "            \n",
    "            # Add to dataset\n",
    "            X.append(chroma_array)\n",
    "            y.append(aligned_chords)\n",
    "            \n",
    "            # Track all unique chords\n",
    "            all_chords.extend(set(aligned_chords))\n",
    "            \n",
    "            processed_songs += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing song {song_id}: {e}\")\n",
    "            failed_songs += 1\n",
    "    \n",
    "    print(f\"Successfully processed {processed_songs} songs, failed to process {failed_songs} songs\")\n",
    "    return X, y, list(set(all_chords))\n",
    "\n",
    "# Let's start with a smaller dataset\n",
    "sample_size = min(100, len(common_ids))\n",
    "song_subset = list(common_ids)[:sample_size]\n",
    "\n",
    "# Build the initial dataset\n",
    "X_songs, y_songs, unique_chords = build_dataset(song_subset, max_songs=sample_size)\n",
    "\n",
    "print(f\"Processed {len(X_songs)} songs\")\n",
    "print(f\"Number of unique chords: {len(unique_chords)}\")\n",
    "print(f\"Some example chords: {unique_chords[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the dataset to frame-level\n",
    "def flatten_dataset(X_songs, y_songs):\n",
    "    \"\"\"Convert song-level dataset to frame-level\"\"\"\n",
    "    X_frames = []\n",
    "    y_frames = []\n",
    "    \n",
    "    for i in range(len(X_songs)):\n",
    "        X_frames.extend(X_songs[i])\n",
    "        y_frames.extend(y_songs[i])\n",
    "        \n",
    "    # Convert to numpy array and ensure correct data type\n",
    "    X_frames_np = np.array(X_frames, dtype=np.float32)\n",
    "    y_frames_np = np.array(y_frames)\n",
    "    \n",
    "    return X_frames_np, y_frames_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have data to process\n",
    "if len(X_songs) > 0:\n",
    "    X_flat, y_flat = flatten_dataset(X_songs, y_songs)\n",
    "\n",
    "    print(f\"Total frames: {len(X_flat)}\")\n",
    "    print(f\"Feature shape: {X_flat.shape}\")\n",
    "    \n",
    "    # Check for any remaining non-finite values\n",
    "    non_finite_count = np.sum(~np.isfinite(X_flat))\n",
    "    if non_finite_count > 0:\n",
    "        print(f\"Warning: {non_finite_count} non-finite values found in the flattened data.\")\n",
    "        # Replace non-finite values with zeros\n",
    "        X_flat = np.nan_to_num(X_flat)\n",
    "        \n",
    "    # Make sure the data is normalized (important for neural networks)\n",
    "    # Chroma features are typically already between 0 and 1, but let's check\n",
    "    max_value = np.max(X_flat)\n",
    "    if max_value > 1.0:\n",
    "        print(f\"Max chroma value is {max_value}, normalizing to [0, 1] range\")\n",
    "        X_flat = X_flat / max_value\n",
    "\n",
    "    # Encode the chord labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    try:\n",
    "        y_encoded = label_encoder.fit_transform(y_flat)\n",
    "        \n",
    "        # Save the label encoder for later use\n",
    "        os.makedirs('models', exist_ok=True)\n",
    "        with open('models/chord_label_encoder.pkl', 'wb') as f:\n",
    "            pickle.dump(label_encoder, f)\n",
    "        \n",
    "        # Get the number of classes\n",
    "        n_classes = len(label_encoder.classes_)\n",
    "        print(f\"Number of chord classes: {n_classes}\")\n",
    "        \n",
    "        # Convert to one-hot encoding\n",
    "        y_onehot = to_categorical(y_encoded, num_classes=n_classes)\n",
    "        \n",
    "        # Split into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_flat, y_onehot, test_size=0.2, random_state=42)\n",
    "        \n",
    "        print(f\"Training set: {X_train.shape}\")\n",
    "        print(f\"Testing set: {X_test.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in encoding labels: {e}\")\n",
    "        print(\"This may be due to empty or invalid chord labels.\")\n",
    "else:\n",
    "    print(\"No data to process. Check the dataset loading steps above for errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count chord occurrences\n",
    "chord_counts = Counter(y_flat)\n",
    "\n",
    "# Get the top 20 chords\n",
    "top_chords = chord_counts.most_common(20)\n",
    "print(\"Top 20 chords:\")\n",
    "for chord, count in top_chords:\n",
    "    print(f\"{chord}: {count}\")\n",
    "\n",
    "# Visualize chord distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "counts = [count for _, count in top_chords]\n",
    "labels = [chord for chord, _ in top_chords]\n",
    "\n",
    "plt.bar(range(len(counts)), counts)\n",
    "plt.xticks(range(len(counts)), labels, rotation=45, ha='right')\n",
    "plt.title('Top 20 Chord Frequencies')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and Train Models\n",
    "\n",
    "def create_feedforward_model(input_shape, n_classes):\n",
    "    \"\"\"Create a simple feedforward neural network optimized for chroma input\"\"\"\n",
    "    model = Sequential([\n",
    "        # Input layer - shape is (12,) for chroma vectors\n",
    "        Dense(128, activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Hidden layers\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_cnn_model(input_shape, n_classes):\n",
    "    \"\"\"Create a 1D CNN model for chroma processing\"\"\"\n",
    "    # For chroma vectors, we reshape to (12, 1) to apply 1D convolutions\n",
    "    model = Sequential([\n",
    "        # Input layer\n",
    "        Input(shape=input_shape),\n",
    "        \n",
    "        # Reshape to have a time dimension (treating the 12 chroma bins as a sequence)\n",
    "        tf.keras.layers.Reshape((input_shape[0], 1)),\n",
    "        \n",
    "        # First conv block\n",
    "        Conv1D(64, kernel_size=3, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Second conv block\n",
    "        Conv1D(128, kernel_size=3, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_lstm_model(input_shape, n_classes):\n",
    "    \"\"\"Create an LSTM model for chroma sequences\"\"\"\n",
    "    # Reshape chroma vectors to sequences\n",
    "    model = Sequential([\n",
    "        # Input layer\n",
    "        Input(shape=input_shape),\n",
    "        \n",
    "        # Reshape to have a time dimension\n",
    "        tf.keras.layers.Reshape((input_shape[0], 1)),\n",
    "        \n",
    "        # LSTM layers\n",
    "        LSTM(128, return_sequences=True),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        LSTM(64),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Dense layers\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Get input shape from training data\n",
    "input_shape = (X_train.shape[1],)\n",
    "print(f\"Input shape for models: {input_shape}\")\n",
    "\n",
    "# Define callbacks for training\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-5, verbose=1),\n",
    "    ModelCheckpoint('models/best_model_checkpoint.h5', save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# Train the feedforward model\n",
    "print(\"\\n--- Training Feedforward Model ---\")\n",
    "\n",
    "ff_model = create_feedforward_model(input_shape, n_classes)\n",
    "print(ff_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ff = ff_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "ff_model.save('models/chord_classifier_feedforward.keras')\n",
    "print(\"Feedforward model saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CNN model\n",
    "\n",
    "cnn_model = create_cnn_model(input_shape, n_classes)\n",
    "print(cnn_model.summary())\n",
    "\n",
    "history_cnn = cnn_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "cnn_model.save('models/chord_classifier_cnn.h5')\n",
    "print(\"CNN model saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the LSTM model\n",
    "\n",
    "lstm_model = create_lstm_model(input_shape, n_classes)\n",
    "print(lstm_model.summary())\n",
    "\n",
    "history_lstm = lstm_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "lstm_model.save('models/chord_classifier_lstm.h5')\n",
    "print(\"LSTM model saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Model Evaluation ---\")\n",
    "    \n",
    "# Function to safely evaluate models\n",
    "def safe_evaluate(model, model_name):\n",
    "    try:\n",
    "        scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "        print(f\"{model_name} - Test Loss: {scores[0]:.4f}, Test Accuracy: {scores[1]:.4f}\")\n",
    "        return scores\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {model_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Evaluate each model if it exists\n",
    "if 'ff_model' in locals():\n",
    "    ff_scores = safe_evaluate(ff_model, \"Feedforward Model\")\n",
    "\n",
    "if 'cnn_model' in locals():\n",
    "    cnn_scores = safe_evaluate(cnn_model, \"CNN Model\")\n",
    "\n",
    "if 'lstm_model' in locals():\n",
    "    lstm_scores = safe_evaluate(lstm_model, \"LSTM Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_history(history, title):\n",
    "    if history is None:\n",
    "        print(f\"No training history available for {title}\")\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Plot accuracy\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title(f'{title} - Accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "        \n",
    "        # Plot loss\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title(f'{title} - Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"models/{title.replace(' ', '_').lower()}_training_history.png\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting history for {title}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histories if available\n",
    "if 'history_ff' in locals():\n",
    "    plot_history(history_ff, 'Feedforward Model')\n",
    "\n",
    "if 'history_cnn' in locals():\n",
    "    plot_history(history_cnn, 'CNN Model')\n",
    "\n",
    "if 'history_lstm' in locals():\n",
    "    plot_history(history_lstm, 'LSTM Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get confusion matrix and classification report\n",
    "def model_analysis(model, X, y, label_encoder, title):\n",
    "    \"\"\"Analyze model performance with confusion matrix and classification report\"\"\"\n",
    "    # Get predictions\n",
    "    y_pred_proba = model.predict(X)\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    y_true = np.argmax(y, axis=1)\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = label_encoder.classes_\n",
    "    \n",
    "    # Create confusion matrix (limit to top N classes for readability)\n",
    "    top_n = 20\n",
    "    top_classes_idx = np.bincount(y_true).argsort()[-top_n:]\n",
    "    \n",
    "    # Filter to only include top classes\n",
    "    mask_true = np.isin(y_true, top_classes_idx)\n",
    "    y_true_filtered = y_true[mask_true]\n",
    "    y_pred_filtered = y_pred[mask_true]\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true_filtered, y_pred_filtered)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        cm, \n",
    "        annot=True, \n",
    "        fmt='d', \n",
    "        cmap='Blues',\n",
    "        xticklabels=[class_names[i] for i in top_classes_idx],\n",
    "        yticklabels=[class_names[i] for i in top_classes_idx]\n",
    "    )\n",
    "    plt.title(f'{title} - Confusion Matrix (Top {top_n} Classes)')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification report\n",
    "    print(f\"\\n{title} - Classification Report:\")\n",
    "    print(classification_report(\n",
    "        y_true, \n",
    "        y_pred, \n",
    "        target_names=class_names,\n",
    "        labels=range(len(class_names)),\n",
    "        zero_division=0\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the best performing model\n",
    "best_model = lstm_model  # Change this based on your results\n",
    "model_analysis(best_model, X_test, y_test, label_encoder, 'Best Model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
